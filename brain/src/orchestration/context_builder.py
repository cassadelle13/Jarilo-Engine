import logging
from typing import List, Dict, Optional


# Построитель контекста - управляет историей и формирует полный контекст для LLM
class ContextBuilder:
    """
    Построитель контекста для Jarilo.
    
    Класс отвечает за сбор и агрегацию дополнительной информации,
    необходимой для полного понимания задачи LLM. Обогащает исходный
    промпт контекстом из истории диалога и системными инструкциями,
    чтобы повысить точность анализа и планирования задачи.
    
    Адаптирована из AutoGen и MemGPT:
        - Сбор истории диалога для контекста
        - Формирование системного промпта
        - Структурированное представление контекста
        - Подготовка полного контекста для передачи в LLM
    
    Роль ContextBuilder:
        - Сбор истории предыдущих взаимодействий
        - Формирование системного промпта для LLM
        - Структурирование контекста для лучшего понимания
        - Подготовка полного контекста перед вызовом LLM
        - Оптимизация размера контекста для LLM
    
    Будущая функциональность:
        - Кэширование часто используемого контекста
        - Интеграция с системой логирования
        - Анализ релевантности сообщений из истории
        - Выбор наиболее важных сообщений при превышении лимита токенов
        - Сжатие длинной истории в краткие резюме
    
    Attributes:
        logger (logging.Logger): Логгер для записи операций.
    """
    
    def __init__(self):
        """
        Инициализирует построитель контекста.
        
        Создает логгер для отслеживания операций построения контекста.
        """
        self.logger = logging.getLogger(__name__)
        self.logger.info("ContextBuilder инициализирован")
    
    def build(
        self,
        original_prompt: str,
        history: Optional[List[Dict[str, str]]] = None
    ) -> str:
        """
        Строит полный контекст на основе исходного промпта и истории.
        
        Метод собирает системный промпт, историю диалога и текущий запрос
        в единый структурированный контекст, готовый для передачи в LLM.
        Это обеспечивает моделью полное понимание задачи и контекста.
        
        Процесс построения контекста (адаптирован из AutoGen/MemGPT):
        1. Инициализация списка частей контекста
        2. Добавление системного промпта, описывающего роль ассистента
        3. Добавление исторических сообщений для контекста
        4. Добавление текущего запроса пользователя
        5. Объединение всех частей в единую строку
        
        Args:
            original_prompt (str): Исходное описание задачи от пользователя.
            history (Optional[List[Dict[str, str]]]): Необязательный список
                                                     сообщений из истории диалога.
                                                     Каждое сообщение должно иметь
                                                     формат: {"role": "...", "content": "..."}
        
        Returns:
            str: Полный контекст, готовый для передачи в LLM. Содержит:
                 - Системный промпт
                 - Историю предыдущих сообщений
                 - Текущий запрос пользователя
        
        Example:
            >>> builder = ContextBuilder()
            >>> history = [
            ...     {"role": "user", "content": "Привет"},
            ...     {"role": "assistant", "content": "Привет! Как дела?"}
            ... ]
            >>> context = builder.build(
            ...     original_prompt="Напиши функцию для вычисления факториала",
            ...     history=history
            ... )
            >>> print(context)
            Ты — ИИ-ассистент, который помогает декомпозировать задачи на шаги.
            
            user: Привет
            
            assistant: Привет! Как дела?
            
            user: Напиши функцию для вычисления факториала
        
        Notes:
            - История используется для предоставления контекста LLM
            - Системный промпт определяет роль и поведение ассистента
            - Разделитель \n\n используется для четкого разделения частей
            - На данном этапе нет ограничения размера контекста
        
        Future Implementation:
            - Добавление проверки лимита токенов
            - Фильтрация релевантных сообщений из истории
            - Сжатие длинной истории в резюме
            - Добавление временных меток к сообщениям
            - Логирование размера сгенерированного контекста
        """
        
        # Инициализация списка для сбора всех частей контекста
        full_context_parts = []
        
        # Добавление системного промпта
        system_prompt = (
            "Ты — ИИ-ассистент, который помогает декомпозировать задачи на шаги. "
            "Твоя роль — анализировать входящие задачи и создавать структурированные планы выполнения, "
            "определяя необходимых агентов и последовательность действий."
        )
        full_context_parts.append(system_prompt)
        
        # Обработка истории диалога
        if history:
            self.logger.debug(f"Добавление истории из {len(history)} сообщений")
            for message in history:
                role = message.get("role", "unknown")
                content = message.get("content", "")
                formatted_message = f"{role}: {content}"
                full_context_parts.append(formatted_message)
        else:
            self.logger.debug("История не предоставлена, используется только системный промпт")
        
        # Добавление текущего запроса пользователя
        current_request = f"user: {original_prompt}"
        full_context_parts.append(current_request)
        
        # Объединение всех частей контекста с разделителем
        full_context = "\n\n".join(full_context_parts)
        
        # Логирование построенного контекста (для отладки)
        self.logger.debug(
            f"Контекст построен. Размер: {len(full_context)} символов, "
            f"частей: {len(full_context_parts)}"
        )
        
        return full_context